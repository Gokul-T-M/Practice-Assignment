import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
from PIL import Image
import torchvision.transforms as transforms
from torchvision import datasets, models
from transformers import BartModel, BartTokenizer
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit
from sklearn.utils.class_weight import compute_class_weight
import matplotlib.pyplot as plt
import numpy as np

# Early Stopping Class
class EarlyStopping:
    def __init__(self, patience=3, delta=0, verbose=False):
        self.patience = patience
        self.delta = delta
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.inf

    def __call__(self, val_loss, model):
        score = -val_loss
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose:
                print(f"EarlyStopping counter: {self.counter} out of {self.patience}")
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        if self.verbose:
            print(f"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...")
        torch.save(model.state_dict(), "checkpoint.pth")
        self.val_loss_min = val_loss

# Load the updated dataset with 179 unique * 3 text data
text_df = pd.read_csv("dataset.csv")  # Ensure the file is in the correct directory
print(text_df.head())
print(text_df['label'].value_counts())

label_list = text_df['label'].unique().tolist()
label2id = {label: idx for idx, label in enumerate(label_list)}
id2label = {idx: label for label, idx in label2id.items()}
text_df['label_id'] = text_df['label'].map(label2id)
print(label2id)
print(text_df.head())

texts = text_df['symptoms'].tolist()
labels = text_df['label_id'].tolist()
train_texts, temp_texts, train_labels, temp_labels = train_test_split(
    texts, labels, test_size=0.30, random_state=42, stratify=labels
)
val_texts, test_texts, val_labels, test_labels = train_test_split(
    temp_texts, temp_labels, test_size=0.50, random_state=42, stratify=temp_labels
)
print(f"Training Samples: {len(train_texts)}, Validation Samples: {len(val_texts)}, Testing Samples: {len(test_texts)}")

model_name = "facebook/bart-base"
tokenizer = BartTokenizer.from_pretrained(model_name)
print("BART Tokenizer initialized")

class TextDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    def __len__(self):
        return len(self.texts)
    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx],
            padding="max_length",
            truncation=True,
            max_length=self.max_length,
            return_tensors="pt"
        )
        item = {key: val.squeeze(0) for key, val in encoding.items()}
        item["labels"] = torch.tensor(self.labels[idx])
        return item
print("TextDataset Class Created")

# Create dataset instances
text_train_dataset = TextDataset(train_texts, train_labels, tokenizer, max_length=128)
text_val_dataset   = TextDataset(val_texts, val_labels, tokenizer, max_length=128)
text_test_dataset  = TextDataset(test_texts, test_labels, tokenizer, max_length=128)
# Create DataLoaders
text_train_loader = DataLoader(text_train_dataset, batch_size=2, shuffle=True)
text_val_loader   = DataLoader(text_val_dataset, batch_size=2, shuffle=False)
text_test_loader  = DataLoader(text_test_dataset, batch_size=2, shuffle=False)
print("Text DataLoaders for Train, Validation, and Test Created!")

from torchvision import transforms
image_transforms = {
    "train": transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ]),
    "val": transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ]),
    "test": transforms.Compose([  # NEW: Added Test Transformations
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
}

print("Image Transforms Defined for Train, Validation, and Test")

image_data_dir = r"C:\Users\gokul\OneDrive\Desktop\MULTIMODAL_AI_EYE_DIS\TRAIN_CODE\colored_images"
image_train_dir = os.path.join(image_data_dir, "train")
image_val_dir   = os.path.join(image_data_dir, "val")
image_test_dir  = os.path.join(image_data_dir, "test")
image_train_dataset = datasets.ImageFolder(image_train_dir, transform=image_transforms["train"])
image_val_dataset   = datasets.ImageFolder(image_val_dir, transform=image_transforms["val"])
image_test_dataset  = datasets.ImageFolder(image_test_dir, transform=image_transforms["test"])
assert set(image_train_dataset.classes) == set(label_list), "Mismatch in classes between text and image datasets."
print("Image Datasets Loaded for Train, Validation, and Test!")

image_train_loader = DataLoader(image_train_dataset, batch_size=16, shuffle=True)
image_val_loader   = DataLoader(image_val_dataset, batch_size=16, shuffle=False)
image_test_loader  = DataLoader(image_test_dataset, batch_size=16, shuffle=False)
print("Image DataLoaders Created for Train, Validation, and Test!")

class MultiModalClassifier(nn.Module):
    def __init__(self, text_model, image_model, text_feat_dim, image_feat_dim, hidden_dim, num_classes):
        super(MultiModalClassifier, self).__init__()
        self.text_model = text_model
        self.image_model = image_model
        self.text_fc = nn.Linear(text_feat_dim, hidden_dim)
        self.image_fc = nn.Linear(image_feat_dim, hidden_dim)
        self.classifier = nn.Linear(hidden_dim, num_classes)
    def forward(self, text_input=None, image_input=None):
        features = None
        if text_input is not None:
            text_input_filtered = {k: v for k, v in text_input.items() if k != "labels"}
            text_outputs = self.text_model(**text_input_filtered)
            pooled_text = text_outputs.last_hidden_state.mean(dim=1)
            text_features = self.text_fc(pooled_text)
            features = text_features if features is None else features + text_features
        if image_input is not None:
            image_features = self.image_model(image_input)
            image_features = self.image_fc(image_features)
            features = image_features if features is None else features + image_features
        if (text_input is not None) and (image_input is not None):
            features = features / 2
        logits = self.classifier(features)
        return logits
print("Multimodal Model Architecture defined")

from transformers import BartModel
import torch.nn as nn
import torchvision.models as models
# Load BART text encoder
text_encoder = BartModel.from_pretrained("facebook/bart-base")
# Load ResNet18 and get feature dimensions
image_encoder = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
image_feat_dim = image_encoder.fc.in_features
# Replace FC layer with Identity to use ResNet as a feature extractor
image_encoder.fc = nn.Identity()
# Define the MultiModalClassifier
hidden_dim = 512
num_classes = len(label_list)
model = MultiModalClassifier(
    text_model=text_encoder,
    image_model=image_encoder,
    text_feat_dim=text_encoder.config.d_model,
    image_feat_dim=image_feat_dim,
    hidden_dim=hidden_dim,
    num_classes=num_classes
)
print("Pretrained encoders loaded, and the multimodal model is initialized.")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
model.to(device)
class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)
class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)
text_criterion = nn.CrossEntropyLoss(weight=class_weights)

image_class_weights = compute_class_weight(
    class_weight='balanced', 
    classes=np.unique(image_train_dataset.targets), 
    y=image_train_dataset.targets
)
image_class_weights = torch.tensor(image_class_weights, dtype=torch.float).to(device)
image_criterion = nn.CrossEntropyLoss(weight=image_class_weights)

optimizer = optim.Adam(model.parameters(), lr=1e-4)
print("Loss and Optimizer Set!")

# Define number of epochs
num_epochs = 6
# Initialize tracking lists
train_loss_history_text = []
val_loss_history_text = []
test_loss_history_text = []
train_loss_history_image = []
val_loss_history_image = []
test_loss_history_image = []
train_acc_history_text = []
val_acc_history_text = []
test_acc_history_text = []
train_acc_history_image = []
val_acc_history_image = []
test_acc_history_image = []
print(f"Training initialized on {device} for {num_epochs} epochs")
print("Loss and accuracy tracking lists created for train, validation, and test sets.")

# Initialize Early Stopping
early_stopping = EarlyStopping(patience=3, verbose=True)

for epoch in range(num_epochs):
    model.train()
    total_loss_text, correct_text, total_text = 0, 0, 0
    total_loss_image, correct_image, total_image = 0, 0, 0
    for batch_idx, (text_batch, image_batch) in enumerate(zip(text_train_loader, image_train_loader)):
        # Process text input
        text_inputs = {key: val.to(device) for key, val in text_batch.items() if key != "labels"}
        text_labels = text_batch["labels"].to(device)
        # Process image input
        image_inputs, image_labels = image_batch[0].to(device), image_batch[1].to(device)
        optimizer.zero_grad()
        # Forward pass for text
        text_outputs = model(text_input=text_inputs, image_input=None)
        text_loss = text_criterion(text_outputs, text_labels)
        # Forward pass for image
        image_outputs = model(text_input=None, image_input=image_inputs)
        image_loss = image_criterion(image_outputs, image_labels)
        # Combine losses before backward pass
        total_loss = text_loss + image_loss
        total_loss.backward()
        optimizer.step()
        # Accumulate training loss and accuracy
        total_loss_text += text_loss.item()
        total_loss_image += image_loss.item()
        text_preds = text_outputs.argmax(dim=1)
        correct_text += (text_preds == text_labels).sum().item()
        total_text += text_labels.size(0)
        image_preds = image_outputs.argmax(dim=1)
        correct_image += (image_preds == image_labels).sum().item()
        total_image += image_labels.size(0)
    # Store training loss/accuracy
    train_loss_text = total_loss_text / len(text_train_loader)
    train_acc_text = 100 * correct_text / total_text
    train_loss_image = total_loss_image / len(image_train_loader)
    train_acc_image = 100 * correct_image / total_image
    train_loss_history_text.append(train_loss_text)
    train_acc_history_text.append(train_acc_text)
    train_loss_history_image.append(train_loss_image)
    train_acc_history_image.append(train_acc_image)
    print(f"Epoch {epoch+1}/{num_epochs} | Text Loss: {train_loss_text:.4f}, Text Acc: {train_acc_text:.2f}% | "
          f"Image Loss: {train_loss_image:.4f}, Image Acc: {train_acc_image:.2f}%")
    ## ðŸ›  **Validation Now Runs Inside the Epoch Loop**
    model.eval()
    total_loss_text, correct_text, total_text = 0, 0, 0
    total_loss_image, correct_image, total_image = 0, 0, 0
    # âœ… Initialize lists to store predictions & labels
    all_val_text_labels = []
    all_val_text_preds = []
    all_val_image_labels = []
    all_val_image_preds = []
    with torch.no_grad():
        for text_batch, image_batch in zip(text_val_loader, image_val_loader):
            # Process text input
            text_inputs = {key: val.to(device) for key, val in text_batch.items() if key != "labels"}
            text_labels = text_batch["labels"].to(device)
            # Process image input
            image_inputs, image_labels = image_batch[0].to(device), image_batch[1].to(device)
            # Forward pass for validation
            text_outputs = model(text_input=text_inputs, image_input=None)
            text_loss = text_criterion(text_outputs, text_labels)
            text_preds = text_outputs.argmax(dim=1)
            image_outputs = model(text_input=None, image_input=image_inputs)
            image_loss = image_criterion(image_outputs, image_labels)
            image_preds = image_outputs.argmax(dim=1)
            # âœ… Store labels & predictions for classification report
            all_val_text_labels.extend(text_labels.cpu().numpy())
            all_val_text_preds.extend(text_preds.cpu().numpy())
            all_val_image_labels.extend(image_labels.cpu().numpy())
            all_val_image_preds.extend(image_preds.cpu().numpy())
            # Accumulate validation loss and accuracy
            total_loss_text += text_loss.item()
            total_loss_image += image_loss.item()
            correct_text += (text_preds == text_labels).sum().item()
            total_text += text_labels.size(0)
            correct_image += (image_preds == image_labels).sum().item()
            total_image += image_labels.size(0)
    val_loss_text = total_loss_text / len(text_val_loader)
    val_acc_text = 100 * correct_text / total_text
    val_loss_image = total_loss_image / len(image_val_loader)
    val_acc_image = 100 * correct_image / total_image
    val_loss_history_text.append(val_loss_text)
    val_acc_history_text.append(val_acc_text)
    val_loss_history_image.append(val_loss_image)
    val_acc_history_image.append(val_acc_image)
    print(f"Validation | Text Loss: {val_loss_text:.4f}, Text Acc: {val_acc_text:.2f}% | "
      f"Image Loss: {val_loss_image:.4f}, Image Acc: {val_acc_image:.2f}%")

    # Early Stopping Check
    early_stopping(val_loss_image, model)
    if early_stopping.early_stop:
        print("Early stopping triggered.")
        break

# ðŸ›  TEST PHASE - Runs after training is complete
model.eval()
total_loss_text, correct_text, total_text = 0, 0, 0
total_loss_image, correct_image, total_image = 0, 0, 0
# âœ… Initialize lists to store test predictions & labels
all_test_text_labels = []
all_test_text_preds = []
all_test_image_labels = []
all_test_image_preds = []
with torch.no_grad():
    for text_batch, image_batch in zip(text_test_loader, image_test_loader):
        # Process text input
        text_inputs = {key: val.to(device) for key, val in text_batch.items() if key != "labels"}
        text_labels = text_batch["labels"].to(device)
        # Process image input
        image_inputs, image_labels = image_batch[0].to(device), image_batch[1].to(device)
        # Forward pass for test data
        text_outputs = model(text_input=text_inputs, image_input=None)
        text_loss = text_criterion(text_outputs, text_labels)
        text_preds = text_outputs.argmax(dim=1)
        image_outputs = model(text_input=None, image_input=image_inputs)
        image_loss = image_criterion(image_outputs, image_labels)
        image_preds = image_outputs.argmax(dim=1)
        # âœ… Store labels & predictions for classification report
        all_test_text_labels.extend(text_labels.cpu().numpy())
        all_test_text_preds.extend(text_preds.cpu().numpy())
        all_test_image_labels.extend(image_labels.cpu().numpy())
        all_test_image_preds.extend(image_preds.cpu().numpy())
        # Accumulate test loss and accuracy
        total_loss_text += text_loss.item()
        total_loss_image += image_loss.item()
        correct_text += (text_preds == text_labels).sum().item()
        total_text += text_labels.size(0)
        correct_image += (image_preds == image_labels).sum().item()
        total_image += image_labels.size(0)
# Compute final test metrics
test_loss_text = total_loss_text / len(text_test_loader)
test_acc_text = 100 * correct_text / total_text
test_loss_image = total_loss_image / len(image_test_loader)
test_acc_image = 100 * correct_image / total_image
# Print final test results
print("\nðŸš€ FINAL TEST RESULTS ðŸš€")
print(f"Test | Text Loss: {test_loss_text:.4f}, Text Acc: {test_acc_text:.2f}% | "
      f"Image Loss: {test_loss_image:.4f}, Image Acc: {test_acc_image:.2f}%")

MODEL_SAVE_PATH = "multimodal_model.pth"
torch.save(model.state_dict(), MODEL_SAVE_PATH)
print(f"Model saved to {MODEL_SAVE_PATH}")

from sklearn.metrics import classification_report, confusion_matrix
# Debug: Ensure variables exist
if "all_val_text_labels" not in globals() or "all_val_text_preds" not in globals():
    raise ValueError("Validation text labels or predictions are not defined. Run the validation step first.")
if "all_test_text_labels" not in globals() or "all_test_text_preds" not in globals():
    raise ValueError("Test text labels or predictions are not defined. Run the test step first.")
# ðŸ“Œ Generate Validation Classification Report (Text)
print("\n=== ðŸ“Š Validation Classification Report (Text) ===")
print(classification_report(all_val_text_labels, all_val_text_preds, labels=list(range(len(label_list))), target_names=label_list))
print("\nConfusion Matrix (Text - Validation):")
print(confusion_matrix(all_val_text_labels, all_val_text_preds))
# ðŸ“Œ Generate Test Classification Report (Text)
print("\n=== ðŸš€ Test Classification Report (Text) ===")
print(classification_report(all_test_text_labels, all_test_text_preds, labels=list(range(len(label_list))), target_names=label_list))
print("\nConfusion Matrix (Text - Test):")
print(confusion_matrix(all_test_text_labels, all_test_text_preds))

from sklearn.metrics import classification_report, confusion_matrix
# Debug: Ensure image validation variables exist
if "all_val_image_labels" not in globals() or "all_val_image_preds" not in globals():
    raise ValueError("Validation image labels or predictions are not defined. Run the validation step first.")
if "all_test_image_labels" not in globals() or "all_test_image_preds" not in globals():
    raise ValueError("Test image labels or predictions are not defined. Run the test step first.")
# ðŸ“Œ Generate Validation Classification Report (Image)
print("\n=== ðŸ“Š Image Validation Classification Report ===")
print(classification_report(all_val_image_labels, all_val_image_preds, 
                            labels=list(range(len(image_val_dataset.classes))), 
                            target_names=image_val_dataset.classes))
print("\nConfusion Matrix (Image - Validation):")
print(confusion_matrix(all_val_image_labels, all_val_image_preds))
# ðŸ“Œ Generate Test Classification Report (Image)
print("\n=== ðŸš€ Test Classification Report (Image) ===")
print(classification_report(all_test_image_labels, all_test_image_preds, 
                            labels=list(range(len(image_test_dataset.classes))), 
                            target_names=image_test_dataset.classes))
print("\nConfusion Matrix (Image - Test):")
print(confusion_matrix(all_test_image_labels, all_test_image_preds))

min_epochs = min(len(train_loss_history_text), len(val_loss_history_text), 
                 len(train_loss_history_image), len(val_loss_history_image), 
                 len(train_acc_history_text), len(val_acc_history_text), 
                 len(train_acc_history_image), len(val_acc_history_image))
epochs_arr = np.arange(1, min_epochs + 1)

import matplotlib.pyplot as plt
import numpy as np
plt.figure(figsize=(14, 6))
# Loss curves
plt.subplot(1, 2, 1)
plt.plot(epochs_arr, train_loss_history_text, 'b-', label="Train Loss (Text)")
plt.plot(epochs_arr, val_loss_history_text, 'b--', label="Val Loss (Text)")
plt.plot(epochs_arr, train_loss_history_image, 'r-', label="Train Loss (Image)")
plt.plot(epochs_arr, val_loss_history_image, 'r--', label="Val Loss (Image)")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training/Validation Loss")
plt.legend()
# Accuracy curves
plt.subplot(1, 2, 2)
plt.plot(epochs_arr, train_acc_history_text, 'b-', label="Train Acc (Text)")
plt.plot(epochs_arr, val_acc_history_text, 'b--', label="Val Acc (Text)")
plt.plot(epochs_arr, train_acc_history_image, 'r-', label="Train Acc (Image)")
plt.plot(epochs_arr, val_acc_history_image, 'r--', label="Val Acc (Image)")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Training/Validation Accuracy")
plt.legend()
plt.tight_layout()
plt.show()